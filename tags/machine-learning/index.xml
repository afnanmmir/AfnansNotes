<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on</title><link>https://afnanmmir.github.io/quartz/tags/machine-learning/</link><description>Recent content in machine learning on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://afnanmmir.github.io/quartz/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Assessing Demographic Bias in Named Entity Recognition</title><link>https://afnanmmir.github.io/quartz/notes/Dem_Bias_Paper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://afnanmmir.github.io/quartz/notes/Dem_Bias_Paper/</guid><description>This paper can be found here
Summary This paper, composed by a group of researchers at twitter, assesses how differences in demographic backgrounds present in text can affect various natural language processing (NLP) models&amp;rsquo; performance in the task of Named Entity Recognition.</description></item><item><title>Backpropagation</title><link>https://afnanmmir.github.io/quartz/notes/BackProp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://afnanmmir.github.io/quartz/notes/BackProp/</guid><description>Before reading this, make sure to read the piece on Gradient Descent, as this will build off of that piece.</description></item><item><title>Stochastic Gradient Descent</title><link>https://afnanmmir.github.io/quartz/notes/GradDesc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://afnanmmir.github.io/quartz/notes/GradDesc/</guid><description>What is Gradient Descent? Gradient descent is an iterative first order optimization algorithm that is used to find local minima (or maxima) of functions.</description></item></channel></rss>